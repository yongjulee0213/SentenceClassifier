{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7GIaJfIn9/oaEHbUGp5ns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongjulee0213/SentenceClassifier/blob/main/klue_robert_small_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nCbIetpnvfR",
        "outputId": "756b02c1-6cba-4aa8-fe36-5a815dadd79c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# for graphing\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8eCI2YsAbwnS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_original = pd.read_csv('/train.csv')\n",
        "train_original.drop(columns=['ID'], inplace=True)\n",
        "test = pd.read_csv('/test.csv')\n",
        "test.drop(columns=['ID'], inplace=True)\n",
        "submission = pd.read_csv('/sample_submission.csv')"
      ],
      "metadata": {
        "id": "zAs5Wmhbjsph"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "CFG = {\n",
        "    'EPOCHS':20,\n",
        "    'LEARNING_RATE':1e-5,\n",
        "    'BATCH_SIZE':16,\n",
        "    'SEED':41\n",
        "}\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "OwrkbRDOjtv2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val, _, _ = train_test_split(train_original, train_original['label'], test_size=0.2, random_state=CFG['SEED'])\n",
        "train = train.reset_index(drop=True)\n",
        "val = val.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "RkblXtIaj1jO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nm = 'klue/roberta-small'\n",
        "base_model = AutoModel.from_pretrained(model_nm)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_nm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkbbQQiRj3OC",
        "outputId": "078d0c9b-96c0-4972-93e0-b952e6a1376c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_len = [len(tokenizer(s)['input_ids']) for s in train['문장']]\n",
        "sns.histplot(tokenizer_len)\n",
        "plt.show()\n",
        "\n",
        "print(f'log value : {np.mean(tokenizer_len)+3*np.std(tokenizer_len)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "KDf8d3ZQj4F8",
        "outputId": "808529bd-6dd2-4774-bda4-3822d44e526f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log value : 90.4092368060602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_log = np.log(tokenizer_len)\n",
        "sns.histplot(tokenizer_log)\n",
        "plt.show()\n",
        "\n",
        "print(f'log value : {np.mean(tokenizer_log)+3*np.std(tokenizer_log)}')\n",
        "print(f'original value : {np.exp(np.mean(tokenizer_log)+3*np.std(tokenizer_log))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "zPRhFmDnj5Yz",
        "outputId": "8289daab-a248-432f-9011-638606c4c372"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log value : 4.8974082584991345\n",
            "original value : 133.94218592094492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJoEIAFqkRKx",
        "outputId": "da5687e4-2322-4da4-c876-ed74c1b3e904"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (embeddings): RobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): RobertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): RobertaPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceTypeDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, labels=None):\n",
        "        texts = dataframe['문장'].values.tolist()\n",
        "\n",
        "        self.texts = [tokenizer(text, padding='max_length', max_length=90, truncation=True, return_tensors='pt') for text in texts]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        if self.labels is not None:\n",
        "            type_tmp = self.labels['type'][idx]\n",
        "            polarity_tmp = self.labels['polarity'][idx]\n",
        "            tense_tmp = self.labels['tense'][idx]\n",
        "            certainty_tmp = self.labels['certainty'][idx]\n",
        "            return text, torch.Tensor(type_tmp), torch.Tensor(polarity_tmp), torch.Tensor(tense_tmp), torch.Tensor(certainty_tmp)\n",
        "        else:\n",
        "            return text, torch.Tensor([-1,-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1])"
      ],
      "metadata": {
        "id": "yoxIxC_Jj6oh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceClassifier(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "        self.klue = base_model # from transformers package\n",
        "\n",
        "        self.fc1 = nn.Linear(768, 16)#large input1024, output1024\n",
        "        self.relu = nn.ReLU()\n",
        "        self.type_clf = nn.Linear(16,4)\n",
        "        self.polarity_clf = nn.Linear(16,3)\n",
        "        self.tense_clf = nn.Linear(16,3)\n",
        "        self.certainty_clf = nn.Linear(16,2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # input_ids : token's id / attention_mask : make a model to focus on which token\n",
        "        klue_out = self.klue(input_ids= input_ids, attention_mask = attention_mask)[0][:,0]\n",
        "\n",
        "        x = self.fc1(klue_out)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        type_output = self.type_clf(x)\n",
        "        type_output = self.softmax(type_output)\n",
        "        polarity_output = self.polarity_clf(x)\n",
        "        polarity_output = self.softmax(polarity_output)\n",
        "        tense_output = self.tense_clf(x)\n",
        "        tense_output = self.softmax(tense_output)\n",
        "        certainty_output = self.certainty_clf(x)\n",
        "        certainty_output = self.softmax(certainty_output)\n",
        "\n",
        "        return type_output, polarity_output, tense_output, certainty_output"
      ],
      "metadata": {
        "id": "KpELEEPMj8GY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_train(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm):\n",
        "    best_val_loss = 99999999999999 # setting max (act as infinity)\n",
        "    early_stopping_threshold_count = 0\n",
        "\n",
        "    criterion = {\n",
        "        'type' : nn.CrossEntropyLoss().to(device),\n",
        "        'polarity' : nn.CrossEntropyLoss().to(device),\n",
        "        'tense' : nn.CrossEntropyLoss().to(device),\n",
        "        'certainty' : nn.CrossEntropyLoss().to(device)\n",
        "    }\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "        \n",
        "        model.train() # sets into the training mode\n",
        "        \n",
        "        for train_input, type_label, polarity_label, tense_label, certainty_label in tqdm(train_dataloader):\n",
        "            attention_mask = train_input['attention_mask'].to(device)\n",
        "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
        "            type_label = type_label.to(device)\n",
        "            polarity_label = polarity_label.to(device)\n",
        "            tense_label = tense_label.to(device)\n",
        "            certainty_label = certainty_label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            type_output, polarity_output, tense_output, certainty_output = model(input_ids, attention_mask) # from the forward function\n",
        "            \n",
        "            loss = 0.25*criterion['type'](type_output, type_label.float()) + \\\n",
        "                   0.25*criterion['polarity'](polarity_output, polarity_label.float()) + \\\n",
        "                   0.25*criterion['tense'](tense_output, tense_label.float()) + \\\n",
        "                   0.25*criterion['certainty'](certainty_output, certainty_label.float())\n",
        "            total_loss_train += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        with torch.no_grad(): # since we should not change gradient for validation \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "            \n",
        "            model.eval() # deactivate training\n",
        "            \n",
        "            # same process as the above\n",
        "            for val_input, vtype_label, vpolarity_label, vtense_label, vcertainty_label in tqdm(val_dataloader):\n",
        "                attention_mask = val_input['attention_mask'].to(device)\n",
        "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                vtype_label = vtype_label.to(device)\n",
        "                vpolarity_label = vpolarity_label.to(device)\n",
        "                vtense_label = vtense_label.to(device)\n",
        "                vcertainty_label = vcertainty_label.to(device)\n",
        "                \n",
        "                vtype_output, vpolarity_output, vtense_output, vcertainty_output = model(input_ids, attention_mask) # from the forward function\n",
        "\n",
        "                loss = 0.25*criterion['type'](vtype_output, vtype_label.float()) + \\\n",
        "                        0.25*criterion['polarity'](vpolarity_output, vpolarity_label.float()) + \\\n",
        "                        0.25*criterion['tense'](vtense_output, vtense_label.float()) + \\\n",
        "                        0.25*criterion['certainty'](vcertainty_output, vcertainty_label.float())\n",
        "\n",
        "                total_loss_val += loss.item()\n",
        "\n",
        "            \n",
        "            print(f'Epochs: {epoch + 1} '\n",
        "                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n",
        "                  f'| Train Accuracy: {total_acc_train / (len(train_dataloader.dataset)): .3f} '\n",
        "                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
        "                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n",
        "            \n",
        "            if best_val_loss > total_loss_val:\n",
        "                best_val_loss = total_loss_val # saving only the best one\n",
        "                torch.save(model, f\"/{model_nm}.pt\")\n",
        "                print(\"Saved model\")\n",
        "                early_stopping_threshold_count = 0\n",
        "            else:\n",
        "                early_stopping_threshold_count += 1 # checking how many epochs have passed that val_loss didn't increase\n",
        "                \n",
        "            if early_stopping_threshold_count >= 3: # ==> patience=1\n",
        "                print(\"Early stopping\")\n",
        "                break"
      ],
      "metadata": {
        "id": "VUuEqGd5j9UD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tmp = train[['문장', '유형', '극성', '시제', '확실성']]\n",
        "train_tmp = pd.get_dummies(train_tmp, columns=['유형', '극성', '시제', '확실성'])#벡터화\n",
        "train_tmp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pbiRpQ6_j_F3",
        "outputId": "9e7541b8-b62b-4140-ecd4-ff8bb6a1fd78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      문장  유형_대화형  유형_사실형  \\\n",
              "0      용산구청 관계자는 ＂재정이 열악한 지자체로서는 1800억원을 마련할 수 없다＂며 서...       0       1   \n",
              "1      부산시는 이처럼 부산이 가파른 상승세를 보이는 이유에 대해 지난해부터 추진하고 있는...       0       1   \n",
              "2      그러나 미숙아, 만성호흡기질환, 선천 심장병, 선천 면역결핍질환, 암환자 등의 고위...       0       1   \n",
              "3                          탁구 종목에서 중국 대표팀 위상이 뛰어나기 때문이다.       0       0   \n",
              "4      이 논문에 따르면 ＇BT-11＇은 뇌의 신경전달물질인 아세틸콜린을 분해하는 효소의 ...       0       1   \n",
              "...                                                  ...     ...     ...   \n",
              "13227                          우리가 익히 아는 대로 임꺽정은 신출귀몰했다.       0       1   \n",
              "13228  김 상무보는 ＂실제 이용자 수와 인당 사용시간 등 주요 데이터가 매년 두 자릿수 상...       0       1   \n",
              "13229  ＇디폴트 옵션＇의 필요성을 주장해온 쪽이 항상 사례로 들어온 것이 ＇401K＇로 불...       1       0   \n",
              "13230  1992년부터 선양시 조선족노인협회를 후원하기 시작해 1997년에는 1500㎡ 건물...       0       1   \n",
              "13231               차량은 고속 상태지만 운전자는 정체모드에서 사고가 많이 발생한다.       0       1   \n",
              "\n",
              "       유형_예측형  유형_추론형  극성_긍정  극성_미정  극성_부정  시제_과거  시제_미래  시제_현재  확실성_불확실  \\\n",
              "0           0       0      1      0      0      1      0      0        0   \n",
              "1           0       0      1      0      0      1      0      0        0   \n",
              "2           0       0      1      0      0      0      0      1        0   \n",
              "3           0       1      1      0      0      0      0      1        0   \n",
              "4           0       0      1      0      0      0      0      1        0   \n",
              "...       ...     ...    ...    ...    ...    ...    ...    ...      ...   \n",
              "13227       0       0      1      0      0      1      0      0        0   \n",
              "13228       0       0      1      0      0      1      0      0        0   \n",
              "13229       0       0      1      0      0      0      0      1        0   \n",
              "13230       0       0      1      0      0      1      0      0        0   \n",
              "13231       0       0      1      0      0      0      0      1        0   \n",
              "\n",
              "       확실성_확실  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  \n",
              "...       ...  \n",
              "13227       1  \n",
              "13228       1  \n",
              "13229       1  \n",
              "13230       1  \n",
              "13231       1  \n",
              "\n",
              "[13232 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94ce6db5-bd53-420e-a2df-58f8dc7794fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>유형_대화형</th>\n",
              "      <th>유형_사실형</th>\n",
              "      <th>유형_예측형</th>\n",
              "      <th>유형_추론형</th>\n",
              "      <th>극성_긍정</th>\n",
              "      <th>극성_미정</th>\n",
              "      <th>극성_부정</th>\n",
              "      <th>시제_과거</th>\n",
              "      <th>시제_미래</th>\n",
              "      <th>시제_현재</th>\n",
              "      <th>확실성_불확실</th>\n",
              "      <th>확실성_확실</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>용산구청 관계자는 ＂재정이 열악한 지자체로서는 1800억원을 마련할 수 없다＂며 서...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>부산시는 이처럼 부산이 가파른 상승세를 보이는 이유에 대해 지난해부터 추진하고 있는...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>그러나 미숙아, 만성호흡기질환, 선천 심장병, 선천 면역결핍질환, 암환자 등의 고위...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>탁구 종목에서 중국 대표팀 위상이 뛰어나기 때문이다.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>이 논문에 따르면 ＇BT-11＇은 뇌의 신경전달물질인 아세틸콜린을 분해하는 효소의 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13227</th>\n",
              "      <td>우리가 익히 아는 대로 임꺽정은 신출귀몰했다.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13228</th>\n",
              "      <td>김 상무보는 ＂실제 이용자 수와 인당 사용시간 등 주요 데이터가 매년 두 자릿수 상...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13229</th>\n",
              "      <td>＇디폴트 옵션＇의 필요성을 주장해온 쪽이 항상 사례로 들어온 것이 ＇401K＇로 불...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13230</th>\n",
              "      <td>1992년부터 선양시 조선족노인협회를 후원하기 시작해 1997년에는 1500㎡ 건물...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13231</th>\n",
              "      <td>차량은 고속 상태지만 운전자는 정체모드에서 사고가 많이 발생한다.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13232 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94ce6db5-bd53-420e-a2df-58f8dc7794fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94ce6db5-bd53-420e-a2df-58f8dc7794fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94ce6db5-bd53-420e-a2df-58f8dc7794fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_type = train_tmp.iloc[:,1:5].values.tolist()\n",
        "train_polarity = train_tmp.iloc[:,5:8].values.tolist()\n",
        "train_tense = train_tmp.iloc[:,8:11].values.tolist()\n",
        "train_certainty = train_tmp.iloc[:,11:13].values.tolist()\n",
        "train_labels = {\n",
        "    'type': train_type,\n",
        "    'polarity': train_polarity,\n",
        "    'tense': train_tense,\n",
        "    'certainty': train_certainty\n",
        "}\n",
        "\n",
        "val_tmp = val[['문장', '유형', '극성', '시제', '확실성']]\n",
        "val_tmp = pd.get_dummies(val_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
        "\n",
        "val_type = val_tmp.iloc[:,1:5].values.tolist()\n",
        "val_polarity = val_tmp.iloc[:,5:8].values.tolist()\n",
        "val_tense = val_tmp.iloc[:,8:11].values.tolist()\n",
        "val_certainty = val_tmp.iloc[:,11:13].values.tolist()\n",
        "val_labels = {\n",
        "    'type': val_type,\n",
        "    'polarity': val_polarity,\n",
        "    'tense': val_tense,\n",
        "    'certainty': val_certainty\n",
        "}"
      ],
      "metadata": {
        "id": "De-y12vOkBZx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(SentenceTypeDataset(train_tmp, tokenizer, train_labels), batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0) # num_workers: how many subprocesses to use for data loading  \n",
        "val_dataloader = DataLoader(SentenceTypeDataset(val_tmp, tokenizer, val_labels), batch_size=CFG['BATCH_SIZE'], num_workers=0)"
      ],
      "metadata": {
        "id": "s6ocnaYikCuq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceClassifier(base_model)"
      ],
      "metadata": {
        "id": "Jx0tQ0DbkEHs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'], 'klue')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCM2KRhSoHk9",
        "outputId": "0dc8d348-27ed-4d88-af4d-ee02b1096dbd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:52<00:00,  7.34it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.768 | Train Accuracy:  0.000 | Val Loss:  0.703 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.46it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.678 | Train Accuracy:  0.000 | Val Loss:  0.660 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.46it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.648 | Train Accuracy:  0.000 | Val Loss:  0.647 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.47it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.636 | Train Accuracy:  0.000 | Val Loss:  0.640 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.46it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.628 | Train Accuracy:  0.000 | Val Loss:  0.635 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:51<00:00,  7.41it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.621 | Train Accuracy:  0.000 | Val Loss:  0.632 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.46it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.614 | Train Accuracy:  0.000 | Val Loss:  0.629 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:51<00:00,  7.45it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.607 | Train Accuracy:  0.000 | Val Loss:  0.627 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.45it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss:  0.605 | Train Accuracy:  0.000 | Val Loss:  0.626 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.46it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss:  0.600 | Train Accuracy:  0.000 | Val Loss:  0.624 | Val Accuracy:  0.000\n",
            "Saved model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:51<00:00,  7.45it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.598 | Train Accuracy:  0.000 | Val Loss:  0.625 | Val Accuracy:  0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.45it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 12 | Train Loss:  0.596 | Train Accuracy:  0.000 | Val Loss:  0.627 | Val Accuracy:  0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [01:50<00:00,  7.47it/s]\n",
            "100%|██████████| 207/207 [00:08<00:00, 24.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 13 | Train Loss:  0.594 | Train Accuracy:  0.000 | Val Loss:  0.630 | Val Accuracy:  0.000\n",
            "Early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_type_predictions(model, loader):\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)\n",
        "    \n",
        "    type_probs, polarity_probs, tense_probs, clarity_probs = [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data_input, _, _, _, _ in tqdm(loader):\n",
        "            attention_mask = data_input['attention_mask'].to(device)\n",
        "            input_ids = data_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "\n",
        "            type_output, polarity_output, tense_output, clarity_output = model(input_ids, attention_mask)\n",
        "            type_probs.append(type_output)\n",
        "            polarity_probs.append(polarity_output)\n",
        "            tense_probs.append(tense_output)\n",
        "            clarity_probs.append(clarity_output)\n",
        "    \n",
        "    return torch.cat(type_probs).cpu().detach().numpy(), \\\n",
        "            torch.cat(polarity_probs).cpu().detach().numpy(), \\\n",
        "            torch.cat(tense_probs).cpu().detach().numpy(), \\\n",
        "            torch.cat(clarity_probs).cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "XY_-RW3Xkgsu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"/klue.pt\")\n",
        "test_dataloader = DataLoader(SentenceTypeDataset(test, tokenizer), batch_size=CFG['BATCH_SIZE'], shuffle=False)"
      ],
      "metadata": {
        "id": "emOBYu7oOqvk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_type, test_pred_polarity, test_pred_tense, test_pred_certainty = get_type_predictions(model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvrl8opaOwGA",
        "outputId": "4847b5c8-a865-4827-dcd4-6fd6be687971"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 444/444 [00:17<00:00, 24.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in test_pred_type]]\n",
        "test_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in test_pred_polarity]]\n",
        "test_tense = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in test_pred_tense]]\n",
        "test_certainty = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in test_pred_certainty]]"
      ],
      "metadata": {
        "id": "LbYkUPNfOzbp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_sum = []\n",
        "for i in range(len(test_type)):\n",
        "    label_sum.append(f'{test_type[i]}-{test_polarity[i]}-{test_tense[i]}-{test_certainty[i]}')\n",
        "\n",
        "submission['label'] = label_sum\n",
        "submission.to_csv('/klue_robert_small_16.csv', index=False)"
      ],
      "metadata": {
        "id": "1yqEwu02O1E-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HeBcRqadO2yz",
        "outputId": "b829295a-d45d-43ca-c21b-3bb359d46caa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID         label\n",
              "0     TEST_0000  사실형-긍정-현재-확실\n",
              "1     TEST_0001  사실형-긍정-현재-확실\n",
              "2     TEST_0002  사실형-긍정-과거-확실\n",
              "3     TEST_0003  사실형-긍정-과거-확실\n",
              "4     TEST_0004  사실형-긍정-과거-확실\n",
              "...         ...           ...\n",
              "7085  TEST_7085  사실형-긍정-현재-확실\n",
              "7086  TEST_7086  추론형-긍정-현재-확실\n",
              "7087  TEST_7087  사실형-긍정-미래-확실\n",
              "7088  TEST_7088  추론형-긍정-과거-확실\n",
              "7089  TEST_7089  사실형-긍정-과거-확실\n",
              "\n",
              "[7090 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f78e03c2-6506-40e0-b676-f6c2cf452f12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>사실형-긍정-현재-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>사실형-긍정-현재-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>사실형-긍정-과거-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>사실형-긍정-과거-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>사실형-긍정-과거-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7085</th>\n",
              "      <td>TEST_7085</td>\n",
              "      <td>사실형-긍정-현재-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7086</th>\n",
              "      <td>TEST_7086</td>\n",
              "      <td>추론형-긍정-현재-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7087</th>\n",
              "      <td>TEST_7087</td>\n",
              "      <td>사실형-긍정-미래-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7088</th>\n",
              "      <td>TEST_7088</td>\n",
              "      <td>추론형-긍정-과거-확실</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7089</th>\n",
              "      <td>TEST_7089</td>\n",
              "      <td>사실형-긍정-과거-확실</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7090 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f78e03c2-6506-40e0-b676-f6c2cf452f12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f78e03c2-6506-40e0-b676-f6c2cf452f12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f78e03c2-6506-40e0-b676-f6c2cf452f12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o53tDf2CZEnh"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}